{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a54a247e",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ea30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=\"2024-10-21\",\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a62acfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector length: 3072\n"
     ]
    }
   ],
   "source": [
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    input=\"Hola mundo\"\n",
    ")\n",
    "\n",
    "vector = response.data[0].embedding\n",
    "print(\"Vector length:\", len(vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc41fcc7",
   "metadata": {},
   "source": [
    "## Tokenizer y función para chunkear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12788686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Usar el nombre de deployment/modelo (definido en la celda de configuración)\n",
    "# AZURE_DEPLOYMENT debe existir en el entorno de ejecución (se definió en la celda anterior)\n",
    "MODEL_FOR_ENCODING = globals().get(\"AZURE_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "\n",
    "# Intentar obtener el encoding para el modelo desplegado; si falla, caer a cl100k_base\n",
    "try:\n",
    "    ENCODER = tiktoken.encoding_for_model(MODEL_FOR_ENCODING)\n",
    "except Exception:\n",
    "    ENCODER = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(ENCODER.encode(text))\n",
    "\n",
    "def chunk_text(text, max_tokens=450, overlap=50):\n",
    "    \"\"\"Divide el texto en chunks usando el encoder del modelo.\n",
    "    Usa ventana deslizante con `overlap` tokens solapados entre chunks.\n",
    "    \"\"\"\n",
    "    tokens = ENCODER.encode(text)\n",
    "    chunks = []\n",
    "\n",
    "    if max_tokens <= 0:\n",
    "        return [text]\n",
    "\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        chunk_tokens = tokens[start:start+max_tokens]\n",
    "        chunk_text = ENCODER.decode(chunk_tokens)\n",
    "        chunks.append(chunk_text)\n",
    "        # avanzar con solapamiento\n",
    "        start += max_tokens - overlap\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62d4d11",
   "metadata": {},
   "source": [
    "## Función para generar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4662d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text: str):\n",
    "    \"\"\"\n",
    "    Generates embeddings using Azure OpenAI (2025 syntax).\n",
    "    Accepts a string or list of strings.\n",
    "    Returns a vector (list of floats).\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\", \n",
    "        input=text\n",
    "    )\n",
    "\n",
    "    # For a single input, return the 1 vector\n",
    "    return response.data[0].embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad8221",
   "metadata": {},
   "source": [
    "## Función general para procesar cada intervención"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34687300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_speech_turn(turn, max_tokens=450):\n",
    "    \"\"\"\n",
    "    Procesa una intervención del discurso:\n",
    "    - Si es pequeña (<= max_tokens): genera embedding directamente.\n",
    "    - Si es grande (> max_tokens): la divide en chunks y genera embeddings para cada chunk\n",
    "    Args:\n",
    "        turn (dict): Diccionario con la intervención del discurso.\n",
    "        max_tokens (int): Número máximo de tokens por chunk.\n",
    "    Returns:\n",
    "        list: Lista de diccionarios con embeddings y metadatos.\n",
    "    \"\"\"\n",
    "    text = turn[\"text\"]\n",
    "    token_count = count_tokens(text)\n",
    "\n",
    "    # Si la intervención es pequeña, solo 1 chunk\n",
    "    if token_count <= max_tokens:\n",
    "        embedding = embed_text(text)\n",
    "        return [{\n",
    "            \"doc_id\": turn[\"doc_id\"],\n",
    "            \"sequence\": turn[\"sequence\"],\n",
    "            \"chunk_id\": None,                      # no hay subdivisión\n",
    "            \"type\": turn[\"type\"],\n",
    "            \"speaker\": turn[\"speaker\"],\n",
    "            \"text\": text,\n",
    "            \"embedding\": embedding,\n",
    "            \"token_count\": token_count\n",
    "        }]\n",
    "\n",
    "    # Si es grande → dividir en chunks\n",
    "    chunks = chunk_text(text, max_tokens)\n",
    "    results = []\n",
    "\n",
    "    for idx, chunk in enumerate(chunks, start=1):\n",
    "        embedding = embed_text(chunk)\n",
    "\n",
    "        results.append({\n",
    "            \"doc_id\": turn[\"doc_id\"],\n",
    "            \"sequence\": turn[\"sequence\"],\n",
    "            \"chunk_id\": idx,                     # 1, 2, 3…\n",
    "            \"type\": turn[\"type\"],\n",
    "            \"speaker\": turn[\"speaker\"],\n",
    "            \"text\": chunk,\n",
    "            \"embedding\": embedding,\n",
    "            \"token_count\": count_tokens(chunk)\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1dbca",
   "metadata": {},
   "source": [
    "## Apply to an intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f27abfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc_id': '2025-01-15-pacic-event', 'sequence': 25, 'type': 'speech_turn', 'speaker': {'raw': 'PRESIDENTA DE MÉXICO, CLAUDIA SHEINBAUM PARDO', 'normalized': 'Claudia Sheinbaum Pardo', 'role': 'Presidenta De México'}, 'text': '—El balón—. DIRECTOR GENERAL DE LA COMISIÓN NACIONAL DE CULTURA FÍSICA Y DEPORTE (CONADE), ROMMEL PACHECO MARRUFO: Le paso el balón al maestro Zoé Robledo. DIRECTOR GENERAL INSTITUTO MEXICANO DEL SEGURO SOCIAL (IMSS), ZOÉ ROBLEDO ABURTO: Muchas gracias. Muy buenos días, Presidenta. Muy buenos días a todos y a todas. En el IMSS estamos preparando 3 Mundialitos y una Copa Internacional con un enfoque: nuevas disciplinas y grupos de población que normalmente no encuentran espacio en el futbol tradicional. La idea es recuperar y ampliar la oferta deportiva en instalaciones del IMSS, y aprovechar el impulso del Mundial para que su práctica crezca y permanezca en nuestro país. El primero es un Torneo de Futsal Femenil, organizado por el IMSS y también por la Secretaría de las Mujeres. Como muchos saben, el futsal o futbol de salón es una práctica que nació en Uruguay en los años ‘30 para jugarse en espacios pequeños, generalmente techados, y combina técnicas de futbol con desplazamientos de baloncesto y la dinámica de pases de balonmano. Se juega 5 contra 5 en cancha corta y con un balón que bota menos, por lo que el juego es más rápido y también más preciso. Y México en este momento, la selección femenil está viviendo un momento importante: este año debutó en el Mundial, en el Campeonato de la Concacaf. Por eso, el Mundialito IMSS Mujeres de Futsal busca que encontremos y también se convierta el Seguro Social en una cantera de talento, sobre todo, de la rama femenil. Aquí vamos a reunir a 181 equipos sub-21, con más de mil 200 futbolistas en 80 municipios de 31 estados. Se jugará, del 1º de febrero al 29 de marzo, en 124 Centros de Seguridad Social y Unidades Deportivas del IMSS. Después, habrá una Supercopa. Y también, la gran final en el Estadio Olímpico Universitario en CU. Habrá también detección de talento bajo estándares de la FIFA. La convocatoria se lanza el 1º de diciembre. El segundo es el Mundialito de Futbol sin Correr o walking futbol . Es una modalidad que se creó en Inglaterra y que busca que personas adultas mayores —desde los 50 años en realidad será nuestra convocatoria— puedan volver y practicar este deporte. La regla del futbol sin correr es muy clara: No se corre. No hay contacto físico agresivo, choques o entradas fuertes. El balón se juega a baja altura, no hay remates de cabeza. Por eso es que está diseñado para personas de mayor edad y también con quienes tienen alguna movilidad reducida, evitando lesiones. Se juega también 5 contra 5. Tiene mucho más pases, más control del balón. Y está ganando mucha popularidad en el mundo y queremos que esta práctica llegue a los Centros Deportivos del Seguro Social. También serán las sedes los 124 Centros de Seguridad Social y Deportivos del IMSS. Esta se jugará del 5 de abril al 3 de mayo. Y también la convocatoria sale el 1º de diciembre. Y el tercer Mundialito organizado es el “Futbol IMSS 21”. Está pensado para niñas y niños con síndrome de Down, es una actividad adaptada con reglas y espacios diseñados para potenciar la seguridad, la integración y el desarrollo físico de las niñas y los niños. Tendremos aquí a 58 equipos jugando en 58 canchas de futbol, 7 del IMSS. También la convocatoria sale el 1º de diciembre. Y por último, la “Copa Internacional Street Child World Cup 2026”. Esta es una copa que se ha celebrado desde el 2010, siempre antes de los Mundiales, la primera vez allá en Sudáfrica y después se ha organizado en los siguientes 3 Mundiales. Es muy significativo porque se organiza entre niñas y niños que han vivido en situación de calle o vulnerabilidad extrema y que encontraron en el futbol una manera de salir adelante. Serán 30 equipos de 24 países en rama varonil y femenil. Y algo importante: en un Mundial, como el del 2026, organizado por 3 naciones, se decidió que fuera en México, pero además en el IMSS, allá en el Centro Vacacional de Oaxtepec, del 5 al 15 de mayo. Será junto con otras actividades y también —algo importante— con la presencia de muchas figuras internacionales que, desde 2010, se han involucrado con esta Copa Internacional para niñas y niños en situación vulnerable. Estas cuatro actividades expresan una misma idea: que el futbol puede abrir la cancha para todas y para todos. Y por la banda izquierda llega Rocío García, directora del DIF, a presentar su plan. Gracias.', 'embedding': None}\n"
     ]
    }
   ],
   "source": [
    "# Import json file \n",
    "import json\n",
    "with open('2025-01-15-pacic-event-structured.json', 'r', encoding='utf-8') as f:\n",
    "    conference_sample = json.load(f)\n",
    "\n",
    "# print json\n",
    "turn_test = conference_sample[24]\n",
    "print(turn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8504218",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = process_speech_turn(turn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b1e84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n",
    "# save result to json file\n",
    "with open('embedding_result.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69c7fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_full_conference(conference_data, max_tokens=450):\n",
    "    \"\"\"\n",
    "    Procesa todas las intervenciones del discurso en los datos de la conferencia.\n",
    "    Args:\n",
    "        conference_data (list): Lista de diccionarios con las intervenciones del discurso.\n",
    "        max_tokens (int): Número máximo de tokens por chunk.\n",
    "    Returns:\n",
    "        list: Lista de diccionarios con embeddings y metadatos para todas las intervenciones.\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "\n",
    "    for turn in conference_data:\n",
    "        embeddings = process_speech_turn(turn, max_tokens)\n",
    "        all_embeddings.extend(embeddings)\n",
    "\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc9b9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed entire conference\n",
    "full_conference_embeddings = embed_full_conference(conference_sample, max_tokens=450)\n",
    "# Save to json file\n",
    "with open('full_conference_embeddings.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(full_conference_embeddings, f, ensure_ascii=False, indent=4) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
